{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis Bike Co with polars-redis\n",
    "\n",
    "This notebook demonstrates how to use **polars-redis** to work with the Redis Bike Co dataset - a fictional bicycle retail company with 111 bikes and 5 stores.\n",
    "\n",
    "We'll cover:\n",
    "1. Loading data into Redis\n",
    "2. Schema inference\n",
    "3. Scanning and querying data\n",
    "4. Using RediSearch for filtering\n",
    "5. Vector similarity search\n",
    "6. Real-world analytics: Finding underpriced inventory\n",
    "7. Performance comparison: polars-redis vs redis-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, make sure you have Redis Stack running:\n",
    "\n",
    "```bash\n",
    "docker run -d --name redis-stack -p 6379:6379 redis/redis-stack:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import polars_redis as redis\n",
    "\n",
    "# Redis connection URL\n",
    "REDIS_URL = \"redis://localhost:6379\"\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data into Redis\n",
    "\n",
    "Let's load the bike and store data from JSON files into Redis using `write_json()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bikes from JSON\n",
    "with open(DATA_DIR / \"bikes.json\") as f:\n",
    "    bikes_raw = json.load(f)[\"data\"]\n",
    "\n",
    "# Flatten the nested structure into a DataFrame\n",
    "bikes_df = pl.DataFrame([\n",
    "    {\n",
    "        \"stockcode\": b[\"stockcode\"],\n",
    "        \"model\": b[\"model\"],\n",
    "        \"brand\": b[\"brand\"],\n",
    "        \"price\": b[\"price\"],\n",
    "        \"type\": b[\"type\"],\n",
    "        \"description\": b[\"description\"],\n",
    "        \"material\": b[\"specs\"][\"material\"],\n",
    "        \"weight\": b[\"specs\"][\"weight\"],\n",
    "    }\n",
    "    for b in bikes_raw\n",
    "])\n",
    "\n",
    "print(f\"Loaded {len(bikes_df)} bikes\")\n",
    "bikes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write bikes to Redis as JSON documents\n",
    "result = redis.write_json(\n",
    "    bikes_df,\n",
    "    url=REDIS_URL,\n",
    "    key_column=\"stockcode\",\n",
    "    key_prefix=\"redisbikeco:bike:\",\n",
    ")\n",
    "\n",
    "print(f\"Wrote {result.success_count} bikes to Redis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and write stores\n",
    "with open(DATA_DIR / \"stores.json\") as f:\n",
    "    stores_raw = json.load(f)[\"data\"]\n",
    "\n",
    "stores_df = pl.DataFrame([\n",
    "    {\n",
    "        \"storecode\": s[\"storecode\"],\n",
    "        \"storename\": s[\"storename\"],\n",
    "        \"city\": s[\"address\"][\"city\"],\n",
    "        \"state\": s[\"address\"][\"state\"],\n",
    "        \"position\": s[\"position\"],\n",
    "        \"amenities\": \",\".join(s[\"amenities\"]),\n",
    "    }\n",
    "    for s in stores_raw\n",
    "])\n",
    "\n",
    "result = redis.write_json(\n",
    "    stores_df,\n",
    "    url=REDIS_URL,\n",
    "    key_column=\"storecode\",\n",
    "    key_prefix=\"redisbikeco:store:\",\n",
    ")\n",
    "\n",
    "print(f\"Wrote {result.success_count} stores to Redis\")\n",
    "stores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Inference\n",
    "\n",
    "polars-redis can automatically infer the schema from your Redis data - no need to manually map types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer schema from bike documents\n",
    "inferred_schema = redis.infer_json_schema(\n",
    "    REDIS_URL,\n",
    "    pattern=\"redisbikeco:bike:*\",\n",
    "    sample_size=10,\n",
    ")\n",
    "\n",
    "print(\"Inferred bike schema:\")\n",
    "for field, dtype in inferred_schema.items():\n",
    "    print(f\"  {field}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get schema with confidence scores - useful for detecting inconsistent data\n",
    "schema_with_confidence = redis.infer_json_schema_with_confidence(\n",
    "    REDIS_URL,\n",
    "    pattern=\"redisbikeco:bike:*\",\n",
    "    sample_size=20,\n",
    ")\n",
    "\n",
    "print(\"Schema inference confidence:\")\n",
    "for field, info in schema_with_confidence.fields.items():\n",
    "    confidence_pct = f\"{info.confidence:.0%}\"\n",
    "    print(f\"  {field}: {info.inferred_type} ({confidence_pct})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scanning Data\n",
    "\n",
    "Use `scan_json()` to lazily read all documents matching a pattern. This is efficient because:\n",
    "- **Lazy evaluation**: Nothing is fetched until you `.collect()`\n",
    "- **Batched fetching**: Documents are retrieved in configurable batches\n",
    "- **Type safety**: Schema is enforced during deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for bikes\n",
    "bike_schema = {\n",
    "    \"stockcode\": pl.Utf8,\n",
    "    \"model\": pl.Utf8,\n",
    "    \"brand\": pl.Utf8,\n",
    "    \"price\": pl.Int64,\n",
    "    \"type\": pl.Utf8,\n",
    "    \"description\": pl.Utf8,\n",
    "    \"material\": pl.Utf8,\n",
    "    \"weight\": pl.Float64,\n",
    "}\n",
    "\n",
    "# Create a lazy scan - nothing fetched yet!\n",
    "bikes_lf = redis.scan_json(\n",
    "    REDIS_URL,\n",
    "    pattern=\"redisbikeco:bike:*\",\n",
    "    schema=bike_schema,\n",
    ")\n",
    "\n",
    "print(f\"LazyFrame created with schema: {bikes_lf.schema}\")\n",
    "print(\"No data fetched yet - this is lazy evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect to execute the scan\n",
    "all_bikes = bikes_lf.collect()\n",
    "\n",
    "print(f\"Total bikes: {len(all_bikes)}\")\n",
    "all_bikes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RediSearch with Query Builder\n",
    "\n",
    "The polars-redis query builder lets you write Pythonic queries that compile to RediSearch syntax.\n",
    "This means **server-side filtering** - only matching documents are transferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis as redis_py\n",
    "\n",
    "r = redis_py.from_url(REDIS_URL)\n",
    "\n",
    "# Drop existing index if present\n",
    "try:\n",
    "    r.execute_command(\"FT.DROPINDEX\", \"bikes_idx\", \"DD\")\n",
    "    print(\"Dropped existing index\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create a comprehensive index\n",
    "r.execute_command(\n",
    "    \"FT.CREATE\", \"bikes_idx\",\n",
    "    \"ON\", \"JSON\",\n",
    "    \"PREFIX\", \"1\", \"redisbikeco:bike:\",\n",
    "    \"SCHEMA\",\n",
    "    \"$.stockcode\", \"AS\", \"stockcode\", \"TAG\",\n",
    "    \"$.model\", \"AS\", \"model\", \"TEXT\",\n",
    "    \"$.brand\", \"AS\", \"brand\", \"TAG\",\n",
    "    \"$.price\", \"AS\", \"price\", \"NUMERIC\", \"SORTABLE\",\n",
    "    \"$.type\", \"AS\", \"type\", \"TAG\",\n",
    "    \"$.description\", \"AS\", \"description\", \"TEXT\",\n",
    "    \"$.material\", \"AS\", \"material\", \"TAG\",\n",
    "    \"$.weight\", \"AS\", \"weight\", \"NUMERIC\", \"SORTABLE\",\n",
    ")\n",
    "\n",
    "print(\"Created bikes_idx index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars_redis.query import col\n",
    "\n",
    "# Simple tag query\n",
    "ebikes = redis.search_json(\n",
    "    REDIS_URL,\n",
    "    index=\"bikes_idx\",\n",
    "    query=col(\"type\") == \"eBikes\",\n",
    "    schema=bike_schema,\n",
    ").collect()\n",
    "\n",
    "print(f\"eBikes found: {len(ebikes)}\")\n",
    "ebikes.select([\"stockcode\", \"brand\", \"model\", \"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex query with multiple conditions\n",
    "# The query builder compiles this to RediSearch syntax\n",
    "query = (\n",
    "    (col(\"type\") == \"Mountain Bikes\") &\n",
    "    (col(\"price\") < 200000) &\n",
    "    (col(\"material\") == \"carbon\")\n",
    ")\n",
    "\n",
    "print(f\"Pythonic query: (col('type') == 'Mountain Bikes') & (col('price') < 200000) & (col('material') == 'carbon')\")\n",
    "print(f\"Compiled to:    {query.to_redis()}\")\n",
    "\n",
    "results = redis.search_json(\n",
    "    REDIS_URL,\n",
    "    index=\"bikes_idx\",\n",
    "    query=query,\n",
    "    schema=bike_schema,\n",
    ").collect()\n",
    "\n",
    "print(f\"\\nFound {len(results)} bikes\")\n",
    "results.select([\"brand\", \"model\", \"price\", \"material\", \"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-text search in descriptions\n",
    "trail_bikes = redis.search_json(\n",
    "    REDIS_URL,\n",
    "    index=\"bikes_idx\",\n",
    "    query=col(\"description\").contains(\"trail\"),\n",
    "    schema=bike_schema,\n",
    ").collect()\n",
    "\n",
    "print(f\"Bikes with 'trail' in description: {len(trail_bikes)}\")\n",
    "trail_bikes.select([\"brand\", \"model\", \"type\", \"description\"]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price range query\n",
    "mid_range = redis.search_json(\n",
    "    REDIS_URL,\n",
    "    index=\"bikes_idx\",\n",
    "    query=col(\"price\").is_between(100000, 200000),\n",
    "    schema=bike_schema,\n",
    ").collect()\n",
    "\n",
    "print(f\"Mid-range bikes (Rs 1000-2000): {len(mid_range)}\")\n",
    "mid_range.select([\"brand\", \"model\", \"type\", \"price\"]).sort(\"price\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vector Similarity Search\n",
    "\n",
    "polars-redis supports vector similarity search using the `knn()` method. This is useful for:\n",
    "- Semantic search (\"find bikes similar to this one\")\n",
    "- Recommendation systems\n",
    "- Anomaly detection\n",
    "\n",
    "First, we need to generate embeddings for our bike descriptions and store them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we'll create simple TF-IDF-like embeddings\n",
    "# In production, you'd use sentence-transformers or OpenAI embeddings\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def simple_embedding(text: str, vocab: dict, dim: int = 64) -> list:\n",
    "    \"\"\"Create a simple bag-of-words embedding.\"\"\"\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    vec = np.zeros(dim)\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            vec[vocab[word] % dim] += 1\n",
    "    # Normalize\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm > 0:\n",
    "        vec = vec / norm\n",
    "    return vec.tolist()\n",
    "\n",
    "# Build vocabulary from all descriptions\n",
    "all_words = []\n",
    "for desc in all_bikes[\"description\"].to_list():\n",
    "    all_words.extend(re.findall(r'\\w+', desc.lower()))\n",
    "\n",
    "vocab = {word: i for i, word in enumerate(set(all_words))}\n",
    "print(f\"Vocabulary size: {len(vocab)} words\")\n",
    "\n",
    "# Generate embeddings for each bike\n",
    "embeddings = [\n",
    "    simple_embedding(desc, vocab)\n",
    "    for desc in all_bikes[\"description\"].to_list()\n",
    "]\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings of dimension {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings to bike data and re-write to Redis\n",
    "bikes_with_embeddings = all_bikes.with_columns(\n",
    "    pl.Series(\"embedding\", embeddings)\n",
    ")\n",
    "\n",
    "# Write updated bikes with embeddings\n",
    "result = redis.write_json(\n",
    "    bikes_with_embeddings,\n",
    "    url=REDIS_URL,\n",
    "    key_column=\"stockcode\",\n",
    "    key_prefix=\"redisbikeco:bike:\",\n",
    ")\n",
    "\n",
    "print(f\"Updated {result.success_count} bikes with embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new index with vector field\n",
    "try:\n",
    "    r.execute_command(\"FT.DROPINDEX\", \"bikes_vector_idx\", \"DD\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "r.execute_command(\n",
    "    \"FT.CREATE\", \"bikes_vector_idx\",\n",
    "    \"ON\", \"JSON\",\n",
    "    \"PREFIX\", \"1\", \"redisbikeco:bike:\",\n",
    "    \"SCHEMA\",\n",
    "    \"$.stockcode\", \"AS\", \"stockcode\", \"TAG\",\n",
    "    \"$.model\", \"AS\", \"model\", \"TEXT\",\n",
    "    \"$.brand\", \"AS\", \"brand\", \"TAG\",\n",
    "    \"$.price\", \"AS\", \"price\", \"NUMERIC\", \"SORTABLE\",\n",
    "    \"$.type\", \"AS\", \"type\", \"TAG\",\n",
    "    \"$.description\", \"AS\", \"description\", \"TEXT\",\n",
    "    \"$.material\", \"AS\", \"material\", \"TAG\",\n",
    "    \"$.weight\", \"AS\", \"weight\", \"NUMERIC\", \"SORTABLE\",\n",
    "    \"$.embedding\", \"AS\", \"embedding\", \"VECTOR\", \"FLAT\", \"6\",\n",
    "        \"TYPE\", \"FLOAT32\",\n",
    "        \"DIM\", \"64\",\n",
    "        \"DISTANCE_METRIC\", \"COSINE\",\n",
    ")\n",
    "\n",
    "print(\"Created bikes_vector_idx with vector field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bikes similar to a query description\n",
    "query_text = \"lightweight carbon bike for trail riding with disc brakes\"\n",
    "query_embedding = simple_embedding(query_text, vocab)\n",
    "\n",
    "print(f\"Query: '{query_text}'\")\n",
    "print(f\"\\nFinding 5 most similar bikes...\")\n",
    "\n",
    "# Use the knn() query builder\n",
    "from polars_redis.query import col\n",
    "\n",
    "knn_query = col(\"embedding\").knn(k=5, vector_param=\"query_vec\")\n",
    "print(f\"\\nKNN Query: {knn_query.to_redis()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute KNN search using raw FT.SEARCH (polars-redis search_json with PARAMS)\n",
    "import struct\n",
    "\n",
    "# Convert embedding to bytes for Redis\n",
    "query_bytes = struct.pack(f\"{len(query_embedding)}f\", *query_embedding)\n",
    "\n",
    "# Execute KNN search\n",
    "results = r.execute_command(\n",
    "    \"FT.SEARCH\", \"bikes_vector_idx\",\n",
    "    \"*=>[KNN 5 @embedding $query_vec]\",\n",
    "    \"PARAMS\", \"2\", \"query_vec\", query_bytes,\n",
    "    \"RETURN\", \"5\", \"stockcode\", \"brand\", \"model\", \"type\", \"description\",\n",
    "    \"DIALECT\", \"2\"\n",
    ")\n",
    "\n",
    "print(f\"Found {results[0]} similar bikes:\\n\")\n",
    "\n",
    "# Parse results\n",
    "for i in range(1, len(results), 2):\n",
    "    key = results[i]\n",
    "    fields = results[i + 1]\n",
    "    field_dict = dict(zip(fields[::2], fields[1::2]))\n",
    "    print(f\"  {field_dict.get('brand', 'N/A')} {field_dict.get('model', 'N/A')} ({field_dict.get('type', 'N/A')})\")\n",
    "    desc = field_dict.get('description', '')[:100]\n",
    "    print(f\"    {desc}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-World Analytics: Finding Underpriced Inventory\n",
    "\n",
    "This is where polars-redis really shines - combining Redis data with Polars analytics.\n",
    "\n",
    "**Business scenario**: Find bikes that are priced below average for their category, adjusted for material quality. These could be:\n",
    "- Pricing errors that need correction\n",
    "- Great deals to promote\n",
    "- Inventory to prioritize for sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fresh data\n",
    "bikes = redis.scan_json(\n",
    "    REDIS_URL,\n",
    "    pattern=\"redisbikeco:bike:*\",\n",
    "    schema=bike_schema,\n",
    ").collect()\n",
    "\n",
    "print(f\"Analyzing {len(bikes)} bikes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate category statistics\n",
    "category_stats = (\n",
    "    bikes\n",
    "    .group_by([\"type\", \"material\"])\n",
    "    .agg(\n",
    "        pl.col(\"price\").mean().alias(\"avg_price\"),\n",
    "        pl.col(\"price\").std().alias(\"std_price\"),\n",
    "        pl.col(\"price\").count().alias(\"count\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Category statistics (type + material):\")\n",
    "category_stats.sort([\"type\", \"material\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join bikes with category stats to find underpriced items\n",
    "bikes_with_stats = bikes.join(\n",
    "    category_stats,\n",
    "    on=[\"type\", \"material\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Calculate price deviation (z-score)\n",
    "underpriced = (\n",
    "    bikes_with_stats\n",
    "    .with_columns(\n",
    "        ((pl.col(\"price\") - pl.col(\"avg_price\")) / pl.col(\"std_price\")).alias(\"price_zscore\"),\n",
    "        ((pl.col(\"avg_price\") - pl.col(\"price\")) / pl.col(\"avg_price\") * 100).alias(\"discount_pct\"),\n",
    "    )\n",
    "    .filter(\n",
    "        (pl.col(\"price_zscore\") < -1) &  # More than 1 std below average\n",
    "        (pl.col(\"count\") >= 3)  # Only categories with enough samples\n",
    "    )\n",
    "    .sort(\"price_zscore\")\n",
    "    .select([\n",
    "        \"stockcode\", \"brand\", \"model\", \"type\", \"material\",\n",
    "        \"price\", \"avg_price\", \"discount_pct\", \"price_zscore\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(f\"Found {len(underpriced)} underpriced bikes (>1 std below category average):\\n\")\n",
    "underpriced.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pricing report\n",
    "pricing_report = (\n",
    "    bikes_with_stats\n",
    "    .with_columns(\n",
    "        ((pl.col(\"price\") - pl.col(\"avg_price\")) / pl.col(\"std_price\")).alias(\"price_zscore\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"price_zscore\") < -1.5)\n",
    "        .then(pl.lit(\"Significantly Underpriced\"))\n",
    "        .when(pl.col(\"price_zscore\") < -0.5)\n",
    "        .then(pl.lit(\"Below Average\"))\n",
    "        .when(pl.col(\"price_zscore\") > 1.5)\n",
    "        .then(pl.lit(\"Premium Priced\"))\n",
    "        .when(pl.col(\"price_zscore\") > 0.5)\n",
    "        .then(pl.lit(\"Above Average\"))\n",
    "        .otherwise(pl.lit(\"Average\"))\n",
    "        .alias(\"pricing_tier\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Summary by pricing tier\n",
    "tier_summary = (\n",
    "    pricing_report\n",
    "    .group_by(\"pricing_tier\")\n",
    "    .agg(\n",
    "        pl.col(\"stockcode\").count().alias(\"count\"),\n",
    "        pl.col(\"price\").mean().alias(\"avg_price\"),\n",
    "    )\n",
    "    .sort(\"avg_price\")\n",
    ")\n",
    "\n",
    "print(\"Pricing tier distribution:\")\n",
    "tier_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best deals by type\n",
    "best_deals = (\n",
    "    pricing_report\n",
    "    .filter(pl.col(\"pricing_tier\") == \"Significantly Underpriced\")\n",
    "    .group_by(\"type\")\n",
    "    .agg(\n",
    "        pl.col(\"stockcode\").count().alias(\"deal_count\"),\n",
    "        pl.col(\"brand\").first().alias(\"example_brand\"),\n",
    "        pl.col(\"model\").first().alias(\"example_model\"),\n",
    "        pl.col(\"price\").min().alias(\"lowest_price\"),\n",
    "    )\n",
    "    .sort(\"deal_count\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"Best deals by bike type:\")\n",
    "best_deals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Comparison: polars-redis vs Traditional Approach\n",
    "\n",
    "Let's compare the performance and code complexity of polars-redis versus the traditional redis-py approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis as redis_py\n",
    "\n",
    "r = redis_py.from_url(REDIS_URL)\n",
    "\n",
    "# Benchmark: Load all bikes and compute stats\n",
    "\n",
    "# --- Traditional approach ---\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Step 1: Get all keys\n",
    "keys = list(r.scan_iter(\"redisbikeco:bike:*\"))\n",
    "\n",
    "# Step 2: Fetch each document one by one\n",
    "bikes_traditional = []\n",
    "for key in keys:\n",
    "    data = r.json().get(key)\n",
    "    if data:\n",
    "        bikes_traditional.append(data)\n",
    "\n",
    "# Step 3: Convert to DataFrame\n",
    "df_traditional = pl.DataFrame(bikes_traditional)\n",
    "\n",
    "# Step 4: Compute stats\n",
    "stats_traditional = (\n",
    "    df_traditional\n",
    "    .group_by(\"type\")\n",
    "    .agg(pl.col(\"price\").mean())\n",
    ")\n",
    "\n",
    "traditional_time = time.perf_counter() - start\n",
    "print(f\"Traditional approach: {traditional_time*1000:.2f}ms\")\n",
    "print(f\"  - {len(keys)} individual Redis calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- polars-redis approach ---\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Single call with batched fetching\n",
    "stats_polars_redis = (\n",
    "    redis.scan_json(\n",
    "        REDIS_URL,\n",
    "        pattern=\"redisbikeco:bike:*\",\n",
    "        schema=bike_schema,\n",
    "    )\n",
    "    .group_by(\"type\")\n",
    "    .agg(pl.col(\"price\").mean())\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "polars_redis_time = time.perf_counter() - start\n",
    "print(f\"polars-redis approach: {polars_redis_time*1000:.2f}ms\")\n",
    "print(f\"  - Batched fetching (fewer round trips)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code complexity comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CODE COMPLEXITY COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "TRADITIONAL (redis-py):\n",
    "------------------------\n",
    "keys = list(r.scan_iter(\"redisbikeco:bike:*\"))\n",
    "bikes = []\n",
    "for key in keys:\n",
    "    data = r.json().get(key)\n",
    "    if data:\n",
    "        bikes.append(data)\n",
    "df = pl.DataFrame(bikes)\n",
    "stats = df.group_by(\"type\").agg(pl.col(\"price\").mean())\n",
    "\n",
    "Lines of code: 7\n",
    "Redis round trips: 1 + N (where N = number of documents)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "POLARS-REDIS:\n",
    "------------------------\n",
    "stats = (\n",
    "    redis.scan_json(REDIS_URL, pattern=\"redisbikeco:bike:*\", schema=bike_schema)\n",
    "    .group_by(\"type\")\n",
    "    .agg(pl.col(\"price\").mean())\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "Lines of code: 5\n",
    "Redis round trips: ~N/batch_size (batched)\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nPerformance: polars-redis was {traditional_time/polars_redis_time:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**polars-redis** provides significant advantages over traditional Redis access patterns:\n",
    "\n",
    "### Less Code, More Power\n",
    "- Write DataFrames directly to Redis with `write_json()`\n",
    "- Infer schemas automatically with `infer_json_schema()`\n",
    "- Scan data lazily with `scan_json()`\n",
    "- Search with a Pythonic query builder\n",
    "\n",
    "### Better Performance\n",
    "- Batched fetching reduces round trips\n",
    "- Server-side filtering with RediSearch\n",
    "- Lazy evaluation defers work until needed\n",
    "\n",
    "### Full Analytics Capability\n",
    "- Seamless integration with Polars for complex analytics\n",
    "- Vector similarity search for semantic queries\n",
    "- Aggregations can run server-side or client-side\n",
    "\n",
    "### Type Safety\n",
    "- Schema inference with confidence scores\n",
    "- Enforced types during deserialization\n",
    "- Early error detection for data quality issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
